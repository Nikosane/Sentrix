# Model_Training.ipynb

# Import necessary libraries
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report

# Load preprocessed data
def load_preprocessed_data(feature_path, label_path):
    """Load the preprocessed features and labels from files."""
    features = pd.read_csv(feature_path)
    labels = pd.read_csv(label_path).values.ravel()
    return features, labels

# Split the dataset into training and testing sets
def split_data(features, labels, test_size=0.2):
    """Split data into training and testing sets."""
    return train_test_split(features, labels, test_size=test_size, random_state=42)

# Train a machine learning model
def train_model(X_train, y_train):
    """Train a Random Forest model."""
    model = RandomForestClassifier(random_state=42)
    model.fit(X_train, y_train)
    return model

# Evaluate the model
def evaluate_model(model, X_test, y_test):
    """Evaluate the model and print a classification report."""
    y_pred = model.predict(X_test)
    print(classification_report(y_test, y_pred))

# Save the trained model
def save_model(model, model_path):
    """Save the trained model to a file."""
    import joblib
    joblib.dump(model, model_path)

# Example usage
def main():
    """Example workflow for training a model."""
    feature_path = 'processed_features.csv'
    label_path = 'processed_labels.csv'
    features, labels = load_preprocessed_data(feature_path, label_path)
    X_train, X_test, y_train, y_test = split_data(features, labels)
    model = train_model(X_train, y_train)
    evaluate_model(model, X_test, y_test)
    save_model(model, 'trained_model.pkl')

if __name__ == "__main__":
    main()
