{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b8e7daf",
   "metadata": {},
   "source": [
    "# Data Preprocessing Notebook\n",
    "This notebook handles data loading, cleaning, preprocessing, and saving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f50d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n",
    "# Load the dataset\n",
    "def load_dataset(file_path):\n",
    "    \"\"\"Load the dataset from a CSV file.\"\"\"\n",
    "    return pd.read_csv(file_path)\n",
    "\n",
    "# Data cleaning and preprocessing\n",
    "def preprocess_data(data):\n",
    "    \"\"\"Perform data cleaning and preprocessing.\"\"\"\n",
    "    # Handling missing values\n",
    "    data = data.dropna()\n",
    "\n",
    "    # Encoding categorical features if any\n",
    "    label_encoders = {}\n",
    "    for column in data.select_dtypes(include=['object']).columns:\n",
    "        le = LabelEncoder()\n",
    "        data[column] = le.fit_transform(data[column])\n",
    "        label_encoders[column] = le\n",
    "\n",
    "    # Feature normalization\n",
    "    scaler = StandardScaler()\n",
    "    features = data.drop('class', axis=1)\n",
    "    labels = data['class']\n",
    "    normalized_features = scaler.fit_transform(features)\n",
    "\n",
    "    return normalized_features, labels, label_encoders\n",
    "\n",
    "# Save preprocessed data to a file\n",
    "def save_preprocessed_data(features, labels, feature_path, label_path):\n",
    "    \"\"\"Save the processed features and labels to files.\"\"\"\n",
    "    pd.DataFrame(features).to_csv(feature_path, index=False)\n",
    "    pd.DataFrame(labels).to_csv(label_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ce8e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Example usage\n",
    "file_path = 'data/kddcup99.csv'  # Update with the actual path to your dataset\n",
    "data = load_dataset(file_path)\n",
    "features, labels, encoders = preprocess_data(data)\n",
    "save_preprocessed_data(features, labels, 'processed_features.csv', 'processed_labels.csv')\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
